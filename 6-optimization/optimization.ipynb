{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Optimization: Gradient Descent\n",
    "\n",
    "_From [Dataflowr Module 4](https://dataflowr.github.io/website/modules/4-optimization-for-deep-learning/) by Marc Lelarge, initially adapted from [Optimization chapter](http://www.d2l.ai/chapter_optimization/) of Dive into Deep Learning._\n",
    "\n",
    "The objective function of an optimization algorithm is usually a loss function based on the training dataset. Hence, the goal of optimization is to reduce the **training error** on the **training dataset**.\n",
    "\n",
    "However, the goal of (deep) learning is to reduce the **generalization error** on the **test dataset**.\n",
    "\n",
    "In order to reduce the generalization error, we need to pay attention to **overfitting** in addition to using the optimization algorithm to reduce the training error.\n",
    "\n",
    "Here we focus specifically on the performance of the optimization algorithm in minimizing the objective function, rather than the model's generalization error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j5yGqm4Nl39f"
   },
   "source": [
    "## Mini-Torch: Tensors and Gradients\n",
    "\n",
    "First things first: to implement SGD, we need to be able to compute the gradient of our loss function.\n",
    "In practice, PyTorch does this automatically for us using _backpropagation_ (see [3-autodiff](3-autodiff/autodiff.ipynb)).\n",
    "\n",
    "### PyTorch Tensors\n",
    "\n",
    "In PyTorch, a `tensor` has a Boolean field `requires_grad` (set to `False` by default) which specifies whether PyTorch will track operations to compute the gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x1 = torch.tensor(-5.0, requires_grad=True)\n",
    "x2 = torch.tensor(-2.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Tensors are objects with a `grad` attribute that stores the gradient computed during the `backward` pass (see [3-autodiff](3-autodiff/autodiff.ipynb))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "x1.requires_grad_(True)\n",
    "x2.requires_grad_(True)\n",
    "\n",
    "print(x1.grad, x2.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Initially the gradients are `None`. \n",
    "Let's try `backward` after computing the result of a simple function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def f_2d(x1, x2):\n",
    "    return 0.1 * x1 ** 2 + 2 * x2 ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "l = f_2d(x1, x2)\n",
    "l.backward()\n",
    "print(x1.grad, x2.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Can you check these results?\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "To understand what happens under the hood, let's reimplement a (very) simplified version of PyTorch's infrastructure.\n",
    "\n",
    "### Tensors and Backprop\n",
    "\n",
    "First, we need to redefine the arithmetic operators to implement the backprop algorithm to compute gradients. You already did most of the work in [tp-3-backprop](3-autodiff/tp-3-backprop.ipynb). We define a class for each operator where the `backward` method implements the local chain rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class Add:\n",
    "    def __init__(self, left, right, result):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.result = result\n",
    "    \n",
    "    def backward(self):\n",
    "        self.left.grad += self.result.grad\n",
    "        self.right.grad += self.result.grad\n",
    "\n",
    "class Mul:\n",
    "    def __init__(self, left, right, result):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.result = result\n",
    "    \n",
    "    def backward(self):\n",
    "        self.left.grad += self.right.value * self.result.grad\n",
    "        self.right.grad += self.left.value * self.result.grad\n",
    "\n",
    "class Pow:\n",
    "    def __init__(self, base, n, result):\n",
    "        self.base = base\n",
    "        self.n = n\n",
    "        self.result = result\n",
    "    \n",
    "    def backward(self):\n",
    "        self.base.grad += self.n * self.base.value ** (self.n - 1) * self.result.grad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Now a `Tensor` is a simple object with a `value` attribute and a `grad` attribute to store the gradient computed by `backward`.\n",
    "\n",
    "Compared to [tp-3-backprop](3-autodiff/tp-3-backprop.ipynb):\n",
    "- We overload the definition of arithmetic operators to directly use the syntax `(x + 2) * 2` (see also [dual_numbers](3-autodiff/dual-numbers.ipynb)).\n",
    "- We store all the operations in an `operations` attribute (instead of using an explicit `MyComposition` with a list of operations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class Tensor:    \n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "        self.grad = 0.0\n",
    "        self.operations = []\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        other = other if isinstance(other, Tensor) else Tensor(other)\n",
    "        result = Tensor(self.value + other.value)\n",
    "        result.operations = self.operations + other.operations + [Add(self, other, result)]\n",
    "        return result\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        other = other if isinstance(other, Tensor) else Tensor(other)\n",
    "        result = Tensor(self.value * other.value)\n",
    "        result.operations = self.operations + other.operations + [Mul(self, other, result)]\n",
    "        return result\n",
    "    \n",
    "    def __pow__(self, n):\n",
    "        result = Tensor(self.value ** n)\n",
    "        result.operations = self.operations + [Pow(self, n, result)]\n",
    "        return result\n",
    "    \n",
    "    def __rmul__(self, other):\n",
    "        return self.__mul__(other)\n",
    "    \n",
    "    def backward(self):\n",
    "        self.grad = 1\n",
    "        for op in reversed(self.operations):\n",
    "            op.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Now let's test it on our simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Optimizer\n",
    "\n",
    "Following PyTorch conventions, we can now define our own `Optimizer` class.\n",
    "An optimizer stores the parameters to optimize (a list of tensors), and we need to define two methods to implement an optimizer:\n",
    "- `zero_grad`: resets the gradient of the parameters (otherwise we accumulate the gradient across multiple steps).\n",
    "- `step`: where the optimization happens, and depends on the algorithm (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        \"\"\"Zero out the gradients of all parameters.\"\"\"\n",
    "        for param in self.params:\n",
    "            param.grad = 0.0\n",
    "\n",
    "    def step(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Now it's time to implement our own optimizers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Gradient Descent\n",
    "\n",
    "In the following, we are trying to minimize a cost function $J(\\theta; x, y)$ with parameters $\\theta$ on a training set $(x, y)$ (containing $n$ elements $(x_i, y_i)$).\n",
    "\n",
    "Even if the problem is not convex, we can still compute the gradient of the cost function $\\nabla J(\\theta)$ with respect to the parameters.\n",
    "\n",
    "We can thus implement a **training loop** where at each step $t$ we update the parameters in the opposite direction of the gradient.\n",
    "The learning rate $\\eta$ determines the size of the steps.\n",
    "\n",
    "- Batch gradient descent: $\\theta_{t+1} = \\theta_t - \\eta \\nabla J(\\theta_t)$\n",
    "- Stochastic gradient descent: $\\theta_{t+1} = \\theta_t - \\eta \\nabla J(\\theta_t; x_i, y_i)$\n",
    "- Mini-batch gradient descent: $\\theta_{t+1} = \\theta_t - \\eta \\nabla J(\\theta_t; x_{i:i+b}, y_{i:i+b})$ (where $b$ is the batch size)\n",
    "\n",
    "\n",
    "Mini-batch gradient descent is the algorithm of choice when training a neural network. \n",
    "The term SGD is usually used also when mini-batches are employed.\n",
    "\n",
    "**Limitations**\n",
    "- Choosing a proper learning rate can be difficult. \n",
    "- How to adapt the learning rate during training?\n",
    "- Why apply the same learning rate to all parameter updates?\n",
    "- How to escape saddle points where the gradient is close to zero in all dimensions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Create grid\n",
    "x_range = np.linspace(-2, 2, 100)\n",
    "y_range = np.linspace(-2, 2, 100)\n",
    "X, Y = np.meshgrid(x_range, y_range)\n",
    "\n",
    "# Saddle function: z = x^2 - y^2\n",
    "Z = X**2 - Y**2\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Surface(\n",
    "        x=x_range,\n",
    "        y=y_range,\n",
    "        z=Z,\n",
    "        colorscale='Viridis',\n",
    "        opacity=0.9\n",
    "    ),\n",
    "    go.Scatter3d(\n",
    "        x=[0],\n",
    "        y=[0],\n",
    "        z=[0],\n",
    "        mode='markers',\n",
    "        marker=dict(size=10, color='red'),\n",
    "        name='Saddle Point'\n",
    "    )\n",
    "])\n",
    "\n",
    "fig.update_layout(\n",
    "    width=600,\n",
    "    height=600,\n",
    "    scene=dict(\n",
    "        xaxis_title='x',\n",
    "        yaxis_title='y',\n",
    "        zaxis_title='z',\n",
    "        aspectmode='cube',\n",
    "        camera=dict(eye=dict(x=1.5, y=1.5, z=1.2))\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "In the rest of this notebook, we will introduce modifications to SGD.\n",
    "We will apply these modifications to mini-batch gradient descent, but to simplify the presentation, in the rest of the notebook we use a toy example and omit the explicit reference to the batch. \n",
    "But keep in mind that in reality, updates are performed for every mini-batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "To illustrate different optimizers, we focus on the simple function `f_2d` that we used to illustrate `backprop` above.\n",
    "\n",
    "$$f(x_1, x_2) = 0.1 \\cdot x_1^2 + 2 \\cdot x_2 ^2$$\n",
    "\n",
    "We want to find the parameters $\\theta^* = (x_1, x_2)$ that minimize $f$. If we look at the surface, the optimization problem is similar to the linear regression in [2-basics](2-basics/linear-regression.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Create grid\n",
    "x1_range = np.linspace(-10, 10, 100)\n",
    "x2_range = np.linspace(-10, 10, 100)\n",
    "X1, X2 = np.meshgrid(x1_range, x2_range)\n",
    "\n",
    "# Compute function values\n",
    "Z = f_2d(X1, X2)\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Surface(\n",
    "        x=x1_range,\n",
    "        y=x2_range,\n",
    "        z=Z,\n",
    "        colorscale='Viridis',\n",
    "        opacity=0.8,\n",
    "        name='Function Surface'\n",
    "    )\n",
    "])\n",
    "\n",
    "fig.update_layout(\n",
    "    width=600,\n",
    "    height=600,\n",
    "    scene=dict(\n",
    "        xaxis_title='x₁',\n",
    "        yaxis_title='x₂',\n",
    "        zaxis_title='f(x₁, x₂)',\n",
    "        camera=dict(eye=dict(x=1.5, y=1.5, z=1.3))\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Here is the training loop for `f_2d`.\n",
    "Thanks to the overloading of arithmetic operators, we can directly call `f_2d` on our tensors, and then use the `backward` method on the result.\n",
    "The code is extremely similar to PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def train(optimizer, x1_init, x2_init, num_steps=20):\n",
    "    x1.value = x1_init\n",
    "    x2.value = x2_init\n",
    "\n",
    "    res = [tuple(p.value for p in optimizer.params)]\n",
    "    \n",
    "    for i in range(num_steps):\n",
    "        # TODO\n",
    "        pass    # Clear gradients\n",
    "                # Forward pass\n",
    "                # Backward pass (populate gradients)\n",
    "                # Update parameters\n",
    "    \n",
    "        res.append(tuple(p.value for p in optimizer.params))\n",
    "    \n",
    "    print('epoch %d, params: %s' % (i+1, res[-1]))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Now let's implement the classic optimizers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Basic SGD\n",
    "\n",
    "The following optimizer implements the most basic gradient descent:\n",
    "\n",
    "$$\\theta_{t+1} = \\theta_t - \\eta \\nabla J(\\theta_t)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "7VfX0pq7l3-q",
    "outputId": "daa4cfd0-d362-41f5-e9e6-77435225d801"
   },
   "outputs": [],
   "source": [
    "class GradientDescent(Optimizer):\n",
    "    \"\"\"Gradient Descent optimizer.\"\"\"\n",
    "    \n",
    "    def __init__(self, params, eta=0.4):\n",
    "        self.eta = eta\n",
    "        super().__init__(params)\n",
    "    \n",
    "    def step(self):\n",
    "        for param in self.params:\n",
    "            pass # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4gJMsVnYl39r"
   },
   "outputs": [],
   "source": [
    "def show_trace_2d(res, color='red'):\n",
    "    \"\"\"Show the trace of 2d variables during optimization.\"\"\"\n",
    "    x1, x2 = zip(*res)\n",
    "    plt.plot(x1, x2, '-o', color=color)\n",
    "    x1_grid = np.arange(-5.5, 3.5, 0.1)\n",
    "    x2_grid = np.arange(min(-3.0, min(x2) - 1), max(1.0, max(x2) + 1), 0.1)\n",
    "    x1_mesh, x2_mesh = np.meshgrid(x1_grid, x2_grid)\n",
    "    \n",
    "    z = 0.1 * x1_mesh ** 2 + 2 * x2_mesh ** 2\n",
    "    \n",
    "    plt.contour(x1_mesh, x2_mesh, z, colors='blue')\n",
    "    plt.xlabel('x1')\n",
    "    plt.ylabel('x2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Depending on the learning rate, we can see oscillations..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code",
    "id": "pcsKwAyRl3-y"
   },
   "outputs": [],
   "source": [
    "gd = GradientDescent([x1, x2], eta=0.4)\n",
    "show_trace_2d(train(gd, x1_init=-5.0, x2_init=-2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Or divergence..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8qnyJQwnl3-0"
   },
   "outputs": [],
   "source": [
    "gd = GradientDescent([x1, x2], eta=0.6)\n",
    "show_trace_2d(train(gd, x1_init=-5.0, x2_init=-2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "text",
    "id": "pT8vz7dKl3-7"
   },
   "source": [
    "### Momentum\n",
    "\n",
    "A first idea is to accelerate SGD by dampening oscillations, i.e., by averaging the last values of the gradient.\n",
    "\n",
    "\\begin{align*}\n",
    "v_{t+1} &= \\gamma v_t + \\eta \\nabla J(\\theta_t)\\\\\n",
    "\\theta_{t+1} &= \\theta_t - v_{t+1}\n",
    "\\end{align*}\n",
    "\n",
    "We have for any $k > 0$:\n",
    "\n",
    "$$\n",
    "v_{t+1} = \\gamma^k v_{t - k} + \\eta \\underbrace{\\sum_{i=0}^k \\gamma^i \\nabla J(\\theta_{t-i})}_{\\text{average of the last gradients}}\n",
    "$$\n",
    "\n",
    "Typical value for $\\gamma = 0.9$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "qylwkBDBl3_C",
    "outputId": "0d1d51e5-778c-412b-bbae-9b7e31ec5595"
   },
   "outputs": [],
   "source": [
    "class Momentum(Optimizer):\n",
    "    \"\"\"Momentum optimizer.\"\"\"\n",
    "    \n",
    "    def __init__(self, params, eta=0.4, gamma=0.5):\n",
    "        self.eta = eta\n",
    "        self.gamma = gamma\n",
    "        super().__init__(params)\n",
    "        # Initialize velocity for each parameter\n",
    "        self.v = [0.0 for _ in self.params]\n",
    "    \n",
    "    def step(self):\n",
    "        for i, param in enumerate(self.params):\n",
    "            pass # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "fSZCrah6l3_K",
    "outputId": "2b006204-3c66-4d9c-c9f1-03ff12ed8483"
   },
   "outputs": [],
   "source": [
    "momentum = Momentum([x1, x2], eta=0.4, gamma=0.5)\n",
    "show_trace_2d(train(momentum, x1_init=-5.0, x2_init=-2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code",
    "id": "6WjZp2WPl3_T"
   },
   "outputs": [],
   "source": [
    "momentum = Momentum([x1, x2], eta=0.6, gamma=0.5)\n",
    "show_trace_2d(train(momentum, x1_init=-5.0, x2_init=-2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s02JrcZRl3_V"
   },
   "outputs": [],
   "source": [
    "momentum = Momentum([x1, x2], eta=0.05, gamma=0.9)\n",
    "show_trace_2d(train(momentum, x1_init=-5.0, x2_init=-2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "text",
    "id": "upxkjOqIl3_b"
   },
   "source": [
    "### Nesterov\n",
    "\n",
    "With momentum, we first compute the gradient and then make a step following our momentum and add the gradient. Nesterov proposed to first make the step following the momentum and then adjust by computing the gradient locally.\n",
    "\n",
    "\\begin{align*}\n",
    "v_{t+1} &= \\gamma v_t + \\eta \\nabla J(\\theta_t - \\gamma v_t)\\\\\n",
    "\\theta_{t+1} &= \\theta_t - v_{t+1}\n",
    "\\end{align*}\n",
    "\n",
    "Unfortunately, this formulation requires computing the gradient at the lookahead position $\\theta_t - \\gamma v_t$, but the optimizer only has access to the gradient at position $\\theta_t$.\n",
    "\n",
    "We can instead use the following reformulation: \n",
    "\n",
    "\\begin{align*} \n",
    "v_{t+1} &= \\gamma v_t + \\eta \\nabla J(\\theta_t)\\\\\n",
    "\\theta_{t+1} &= \\theta_t - \\gamma v_{t+1} - \\eta \\nabla J(\\theta_t) \n",
    "\\end{align*} \n",
    "\n",
    "We compute the gradient at the current position $\\theta_t$ and apply both the momentum term $\\gamma v_{t+1}$ and the gradient term $\\eta \\nabla J(\\theta_t)$ directly to the parameters. The two formulations are mathematically equivalent through the change of variables: $\\tilde{\\theta}_t = \\theta_t - \\gamma v_t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code",
    "id": "RyzF7aAXl3_h"
   },
   "outputs": [],
   "source": [
    "class Nesterov(Optimizer):\n",
    "    \"\"\"Nesterov Accelerated Gradient optimizer.\"\"\"\n",
    "    \n",
    "    def __init__(self, params, eta=0.05, gamma=0.9):\n",
    "        self.eta = eta\n",
    "        self.gamma = gamma\n",
    "        super().__init__(params)\n",
    "        # Initialize velocity for each parameter\n",
    "        self.v = [0.0 for _ in self.params]\n",
    "    \n",
    "    def step(self):\n",
    "        for i, param in enumerate(self.params):\n",
    "            pass # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Mk4sixgl3_i"
   },
   "outputs": [],
   "source": [
    "nesterov = Nesterov([x1, x2], eta=0.05, gamma=0.9)\n",
    "show_trace_2d(train(nesterov, x1_init=-5.0, x2_init=-2.0))\n",
    "\n",
    "momentum = Momentum([x1, x2], eta=0.05, gamma=0.9)\n",
    "show_trace_2d(train(momentum, x1_init=-5.0, x2_init=-2.0), color='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "text",
    "id": "TVc4sPtFl3_o"
   },
   "source": [
    "### Adagrad\n",
    "\n",
    "Another idea is to adapt our updates to each individual parameter, i.e., have a different decreasing learning rate for each parameter.\n",
    "\n",
    "\\begin{align*}\n",
    "s_{t+1,i} &= s_{t,i} + \\nabla J(\\theta_t)_i^2\\\\\n",
    "\\theta_{t+1,i} &= \\theta_{t,i} - \\frac{\\eta}{\\sqrt{s_{t+1,i} + \\epsilon}} \\nabla J(\\theta_t)_i\n",
    "\\end{align*}\n",
    "\n",
    "No manual tuning of the learning rate required.\n",
    "\n",
    "Typical default values: $\\eta = 0.01$ and $\\epsilon = 1e-8$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "XY90pzoLl3_v",
    "outputId": "4ac7254c-9ebb-4de2-f50e-02724cd5655b"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class Adagrad(Optimizer):\n",
    "    \"\"\"Adagrad optimizer.\"\"\"\n",
    "    \n",
    "    def __init__(self, params, eta=0.4, eps=1e-6):\n",
    "        self.eta = eta\n",
    "        self.eps = eps\n",
    "        super().__init__(params)\n",
    "        # Initialize accumulated squared gradients for each parameter\n",
    "        self.s = [0.0 for _ in self.params]\n",
    "    \n",
    "    def step(self):\n",
    "        for i, param in enumerate(self.params):\n",
    "            pass # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code",
    "id": "RtU9tLiml3_2"
   },
   "outputs": [],
   "source": [
    "adagrad = Adagrad([x1, x2], eta=0.4)\n",
    "show_trace_2d(train(adagrad, x1_init=-5.0, x2_init=-2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OBbRL5h3l3_3"
   },
   "outputs": [],
   "source": [
    "adagrad = Adagrad([x1, x2], eta=2)\n",
    "show_trace_2d(train(adagrad, x1_init=-5.0, x2_init=-2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "text",
    "id": "nc3_6I-Ul3_9"
   },
   "source": [
    "### RMSProp\n",
    "\n",
    "Unfortunately, with Adagrad the learning rate goes to zero and never forgets about the past.\n",
    "Idea proposed by G. Hinton in his Coursera class: use exponential average.\n",
    "\n",
    "\\begin{align*}\n",
    "s_{t+1,i} &= \\gamma s_{t,i} + (1-\\gamma)\\nabla J(\\theta_t)_i^2\\\\\n",
    "\\theta_{t+1,i} &= \\theta_{t,i} - \\frac{\\eta}{\\sqrt{s_{t+1,i} + \\epsilon}} \\nabla J(\\theta_t)_i\n",
    "\\end{align*}\n",
    "\n",
    "Typical default values: $\\gamma = 0.9$ and $\\eta = 0.001$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code",
    "id": "BD9ILdGVl4AD"
   },
   "outputs": [],
   "source": [
    "class RMSProp(Optimizer):\n",
    "    \"\"\"RMSProp optimizer.\"\"\"\n",
    "    \n",
    "    def __init__(self, params, eta=0.4, gamma=0.9, eps=1e-6):\n",
    "        self.eta = eta\n",
    "        self.gamma = gamma\n",
    "        self.eps = eps\n",
    "        super().__init__(params)\n",
    "        # Initialize exponential moving average of squared gradients\n",
    "        self.s = [0.0 for _ in self.params]\n",
    "    \n",
    "    def step(self):\n",
    "        for i, param in enumerate(self.params):\n",
    "            pass # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vC3McRDZl4AF"
   },
   "outputs": [],
   "source": [
    "rmsprop = RMSProp([x1, x2], eta=0.4, gamma=0.9)\n",
    "show_trace_2d(train(rmsprop, x1_init=-5.0, x2_init=-2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "text",
    "id": "rT5IwhY8l4AK"
   },
   "source": [
    "## Adam\n",
    "\n",
    "Mixing ideas from RMSProp and momentum, we get Adam = Adaptive Moment Estimation (that you used in [TP-5](5-CNN/tp-5-cnn.ipynb)).\n",
    "\n",
    "\\begin{align*}\n",
    "m_{t+1,i} &= \\beta_1 m_{t,i} + (1-\\beta_1)\\nabla J(\\theta_t)_i\\\\\n",
    "v_{t+1,i} &= \\beta_2 v_{t,i} + (1-\\beta_2)\\nabla J(\\theta_t)_i^2\\\\\n",
    "\\hat{m}_{t+1,i} &= \\frac{m_{t+1,i}}{1-\\beta_1^{t+1}}\\\\\n",
    "\\hat{v}_{t+1,i} &= \\frac{v_{t+1,i}}{1-\\beta_2^{t+1}}\\\\\n",
    "\\theta_{t+1,i} &= \\theta_{t,i} - \\frac{\\eta}{\\sqrt{\\hat{v}_{t+1,i}} + \\epsilon} \\hat{m}_{t+1,i}\n",
    "\\end{align*}\n",
    "\n",
    "$\\hat{m}_t$ and $\\hat{v}_t$ are estimates for the first and second moments of the gradients. \n",
    "Because $m_0 = v_0 = 0$, these estimates are biased towards $0$. The factors $\\frac{1}{(1 - \\beta^{t+1})}$ are here to counteract these biases.\n",
    "\n",
    "Typical values: $\\beta_1 = 0.9$, $\\beta_2 = 0.999$, and $\\epsilon = 1e-8$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "id": "oeQbFML-l4AV",
    "outputId": "f176b4af-3840-41ca-e544-6e19bd596e5d"
   },
   "outputs": [],
   "source": [
    "class Adam(Optimizer):\n",
    "    \"\"\"Adam optimizer.\"\"\"\n",
    "    \n",
    "    def __init__(self, params, eta=0.8, beta1=0.9, beta2=0.99, eps=1e-6):\n",
    "        self.eta = eta\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.eps = eps\n",
    "        super().__init__(params)\n",
    "        # Initialize first and second moment estimates\n",
    "        self.m = [0.0 for _ in self.params]\n",
    "        self.v = [0.0 for _ in self.params]\n",
    "        self.t = 0\n",
    "    \n",
    "    def step(self):\n",
    "        self.t += 1\n",
    "        for i, param in enumerate(self.params):\n",
    "            pass # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "colab_type": "code",
    "id": "WmJEncF-l4Ag",
    "outputId": "b99469a0-f719-45e4-9d5e-fd11bcebf9df"
   },
   "outputs": [],
   "source": [
    "adam = Adam([x1, x2], eta=0.8)\n",
    "show_trace_2d(train(adam, x1_init=-5.0, x2_init=-2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "text",
    "id": "mQQ1o7Yql4Al"
   },
   "source": [
    "## AMSGrad\n",
    "\n",
    "Sometimes, Adam forgets too fast. To fix this, we replace the moving average with a max.\n",
    "\n",
    "\\begin{align*}\n",
    "m_{t+1,i} &= \\beta_1 m_{t,i} + (1-\\beta_1)\\nabla J(\\theta_t)_i\\\\\n",
    "v_{t+1,i} &= \\beta_2 v_{t,i} + (1-\\beta_2)\\nabla J(\\theta_t)_i^2\\\\\n",
    "\\hat{v}_{t+1,i} &= \\max(\\hat{v}_{t,i}, v_{t+1,i})\\\\\n",
    "\\theta_{t+1,i} &= \\theta_{t,i} - \\frac{\\eta}{\\sqrt{\\hat{v}_{t+1,i}} + \\epsilon} m_{t+1,i}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class AMSGrad(Optimizer):\n",
    "    \"\"\"AMSGrad optimizer.\"\"\"\n",
    "    \n",
    "    def __init__(self, params, eta=1.0, beta1=0.9, beta2=0.99, eps=1e-6):\n",
    "        self.eta = eta\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.eps = eps\n",
    "        super().__init__(params)\n",
    "        # Initialize first and second moment estimates, and max second moment\n",
    "        self.m = [0.0 for _ in self.params]\n",
    "        self.v = [0.0 for _ in self.params]\n",
    "        self.v_max = [0.0 for _ in self.params]\n",
    "        self.t = 0\n",
    "    \n",
    "    def step(self):\n",
    "        self.t += 1\n",
    "        for i, param in enumerate(self.params):\n",
    "            pass # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "amsgrad = AMSGrad([x1, x2], eta=1)\n",
    "show_trace_2d(train(amsgrad, x1_init=-5.0, x2_init=-2.0))\n",
    "\n",
    "\n",
    "adam = Adam([x1, x2], eta=1)\n",
    "show_trace_2d(train(adam, x1_init=-5.0, x2_init=-2.0), color='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Want more? See also [Sebastien Ruder \"An overview of gradient descent optimization algorithms\" (2016)](https://www.ruder.io/optimizing-gradient-descent/)\n",
    "\n",
    "### PyTorch Optimizers\n",
    "\n",
    "All these optimizers are implemented in PyTorch in [torch.optim](https://docs.pytorch.org/docs/stable/optim.html).\n",
    "The implementation is similar to our own.\n",
    "The constructors take as arguments:\n",
    "- A list of parameters to optimize (can be obtained from a module with `module.parameters()`).\n",
    "- The hyperparameters `lr`, `momentum`, etc. The default values are different for all optimizers—check the documentation."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Gradient_descent_optimization_algorithms_empty_colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "2025-m2-idl (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
